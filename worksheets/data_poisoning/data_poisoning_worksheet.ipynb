{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75cc593b",
   "metadata": {},
   "source": [
    "# Data Poisoning\n",
    "\n",
    "read article: https://www.promptfoo.dev/blog/rag-poisoning/  for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a215f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For this worksheet we have created a wrapper around chromadb to simplify the worksheet\n",
    "TODO: take a look at the source to see how it is implemented\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "import openai\n",
    "\n",
    "GPT_4 = 'gpt-4-turbo' # 128,000 tokens\n",
    "\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.chroma_db import VectorCollection, VectorDBItem, OpenAIEmbeddingModel, get_chromadb_client, remove_collection\n",
    "SCHEMA_NAME = \"data_poisoning_embedding\"\n",
    "OPENAI_API_KEY = #TODO\n",
    "chroma_client = get_chromadb_client(SCHEMA_NAME)\n",
    "client_openai = openai.OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "def load_example_text()->str:\n",
    "    with open(\"example_document.txt\", \"r\") as file:\n",
    "        txt = file.read()\n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad08a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: run cell -> to populate vector store with the chunks created in the cell above\n",
    "\"\"\"\n",
    "\n",
    "COLLECTION_USER_EXPERIMENTAL_NAME = \"poisoning_experimental\"\n",
    "\n",
    "\n",
    "def drop_and_populate_collection(collection: VectorCollection, chunks: List[str], chroma_client)->None:\n",
    "    remove_collection(chroma_client, COLLECTION_USER_EXPERIMENTAL_NAME)\n",
    "    print(f\"going to embed {len(chunks)} chunks\")\n",
    "    for index, chunk in enumerate(chunks):\n",
    "        print(f\"adding chunk {index}\")\n",
    "        collection.add_item(chunk, f\"id_{index}\")\n",
    "\n",
    "collection_user_experimental = VectorCollection(COLLECTION_USER_EXPERIMENTAL_NAME,\n",
    "                                                chroma_client,\n",
    "                                                OPENAI_API_KEY,\n",
    "                                                embedding_model=OpenAIEmbeddingModel.ADA_002)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce5dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    \"a pragmatic guide to dealing with data - a comprehensive overview of data management\",\n",
    "    \"data systems and algorithms - a comprehensive overview of data management\",\n",
    "    \"data processing in the age of AI- a comprehensive overview of data management\",\n",
    "    \"data for dummies - a comprehensive overview of data management\",\n",
    "    \"integration of data systems and IOT - a comprehensive overview of data management\",\n",
    "    \"Important Urgent Important Urgent Data book - a book written by rushil daya\",\n",
    "    \"dealing with big data - a comprehensive overview of data management\"\n",
    "]\n",
    "\n",
    "drop_and_populate_collection(collection_user_experimental, documents, chroma_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f1ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"I am looking for a book on data\"\n",
    "\n",
    "closest_items = collection_user_experimental.similar_items(search_term, n_results=3)\n",
    "\n",
    "for item in closest_items:\n",
    "    print(f\"distance_to_search_term: {item.distance}, id: {item.id} ,item: {item.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1f0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(prompt:str, model)->Tuple[str, float]:\n",
    "    api_response = client_openai.chat.completions.create(\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    return (api_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf010d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_with_context = f\"\"\"\n",
    "answer the users question giving priority to the context provided in the following list of documents:\n",
    "{[str(index)+': '+item.text+'\\n' for index, item in enumerate(closest_items)]}\n",
    "User question: {search_term}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d103ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_response(prompt_with_context, GPT_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e08152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO add a filter on the list to try and remove the poisoned document making it as robust as possible\n",
    "# add more documents examples of poisoned documents to test your filter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaia_rag_workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
