{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "476aa692",
   "metadata": {},
   "source": [
    "# Reranking\n",
    "For a more indepth explaination of rerankers read the following article : https://www.pinecone.io/learn/series/rag/rerankers/\n",
    "\n",
    "In short, when doing RAG, we must be aware that LLMs do not treat recall all information in there context windows equally well.\n",
    "Documents closest to the \"edges\" of the provided context window will be most accuratelly used by the LLM. thus, there is value\n",
    "in arranging the context we provide to the LLM by putting what we consider the most relevant pieces of context on the edges (typically\n",
    "the start only) of the prompt\n",
    "\n",
    "while vector similarity already attempts to do this - using specialised rerankers on the subset returned by the retrieval process\n",
    "typically can yield better results as while the embedding process is more generic and does not have the context of the search query with\n",
    "reranking we do have this available\n",
    "\n",
    "we cannot simply use a reranker against all documents (bypass embedding) as this process will to computationally intensive at runtime \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"context.webp\" width=\"500\"/> <img src=\"reranker.webp\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b989b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.ClientV2(api_key=\"\")#todo\n",
    "\n",
    "def rerank_and_display(documents:list[str], query:str, top_n:int=3)->list[str]:\n",
    "    response = co.rerank(\n",
    "        model=\"rerank-v3.5\",\n",
    "        query=query,\n",
    "        documents=documents,\n",
    "        top_n=top_n,\n",
    "    )\n",
    "\n",
    "    ranked_docs = sorted(response.results, key=lambda x: x.relevance_score, reverse=True)\n",
    "    for item in ranked_docs:\n",
    "        print(f\"Document: {item.index}, Score: {item.relevance_score}, Document Text: {documents[item.index]}\")\n",
    "\n",
    "    return ranked_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run this example, change the documents and the query to see how the rankings change\n",
    "docs = [\n",
    "    \"the capital city of south africa is pretoria\",\n",
    "    \"the largest city in south africa is johannesburg\",\n",
    "    \"the official languages of south africa are eleven\",\n",
    "    \"the currency used in south africa is the rand\",\n",
    "    \"south africa is known for its diverse culture and history\",\n",
    "    \"the largest city in the world is tokyo\"\n",
    "]\n",
    "\n",
    "rankings = rerank_and_display(docs, \"where in south africa would i find the most people\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84b3a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Optional\n",
    "# combine vector retrieval with reranking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaia_rag_workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
