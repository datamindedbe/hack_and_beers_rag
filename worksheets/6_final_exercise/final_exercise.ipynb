{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40d93e67",
   "metadata": {},
   "source": [
    "# Final Exercise\n",
    "\n",
    "This exercise is about bringing together what you have learnt in the previous exercise\n",
    "\n",
    "In the source_documents folder are a number of CV's of fictional people.\n",
    "\n",
    "The first task would be to embed this data into a vector database, secondly create a retrieval and generation function which will make use of this data.\n",
    "\n",
    "You can make the RAG step as simple or as complex as you like - consider some of the following questions:\n",
    "\n",
    "* how best to chunk the data?\n",
    "* what information to pass to the generation step? is any preprocessing/augmentation needed\n",
    "* are there any metrics you can incorporate to your pipeline at runtime? (NOTE: avoid using recall as this can become computationally expensive)\n",
    "* what possible data posioning attacks might be relevent to this exercise? How, can you protect against them?\n",
    "* ... be creative and think of other improvements you may like to implement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc7d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial setup\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import openai\n",
    "import glob\n",
    "import dotenv\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "from src.utils import OPENAI_API_KEY\n",
    "from src.chroma_db import VectorCollection, VectorDBItem, OpenAIEmbeddingModel, get_chromadb_client, remove_collection\n",
    "\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "OPENAI_MODEL = 'gpt-4-turbo' # 128,000 tokens\n",
    "SCHEMA_NAME = \"final_exercise_embeddings\"\n",
    "COLLECTION_NAME = \"final_exercise_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee81af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = get_chromadb_client(SCHEMA_NAME)\n",
    "client_openai = openai.OpenAI(\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "collection = VectorCollection(\n",
    "    name=COLLECTION_NAME,\n",
    "    client=chroma_client, \n",
    "    token=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2382e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_documents():\n",
    "    \"\"\" A very simple method to obtain all documents as a list\"\"\"\n",
    "    documents = []\n",
    "    for file_path in glob.glob(\"source_documents/*.md\"):\n",
    "        with open(file_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            doc_id = file_path.split('/')[-1].replace('.md', '')\n",
    "            documents.append((doc_id, content))\n",
    "    return documents\n",
    "\n",
    "\n",
    "documents = load_documents()\n",
    "for doc_id, content in documents:\n",
    "    collection.add_item(content, doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b0924",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Try to implement one of the chunking methods to improve the performance of your RAG!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def chunk(document):\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ae2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def retrieve(query, top_k):\n",
    "    \"\"\" A method to retrieve topK results similar to the given query \"\"\"\n",
    "\n",
    "    results = collection.similar_items(query, n_results=top_k)\n",
    "    return [result.text for result in results]\n",
    "\n",
    "\n",
    "\n",
    "def generate(query, context, max_tokens=500):\n",
    "    \"\"\" Wrapper on the OpenAI generation method, which combines the retrieved context together with the user query \"\"\"\n",
    "\n",
    "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\n",
    "    response = client_openai.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "def rag(query, top_k=3):\n",
    "    \"\"\" The entire RAG pipeline (Retrieve from VectorDB -> Generate) \"\"\"\n",
    "    \n",
    "    retrieved_docs = retrieve(query, top_k)\n",
    "    context = \"\\n\\n\".join(retrieved_docs)\n",
    "\n",
    "    return generate(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5289dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Given your situation with a car breakdown, David \"Dusty\" Miller would be best suited to help you. With his background as a mechanic and his practical skills in vehicle maintenance and repair, Dusty has the expertise necessary to diagnose and fix problems with cars, especially given his experience and passion for restoring vintage vehicles. You can be confident that Dusty's mechanical skills will come in handy in getting your car back up and running."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = rag(\"My car broke down. Who can help me?\")\n",
    "\n",
    "display(Markdown(answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaia-rag-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
