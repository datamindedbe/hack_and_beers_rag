{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1854a61a",
   "metadata": {},
   "source": [
    "# Vector Embedding\n",
    "\n",
    "The purpose of this worksheet is to gain familiarity with vector embeddings and \n",
    "gaining an intuition about vector space.\n",
    "we make use of chromadb which is a lightweight vector database for these examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6023475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial setup\n",
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from src.utils import OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87478377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For this worksheet we have created a wrapper around chromadb to simplify the worksheet\n",
    "TODO: take a look at the source to see how it is implemented\n",
    "\"\"\"\n",
    "\n",
    "from typing import List\n",
    "from src.chroma_db import VectorCollection, OpenAIEmbeddingModel, get_chromadb_client, remove_collection\n",
    "\n",
    "SCHEMA_NAME = \"worksheet_vector_embedding\"\n",
    "chroma_client = get_chromadb_client(SCHEMA_NAME)\n",
    "\n",
    "def load_example_text()->str:\n",
    "    with open(\"example_document.txt\", \"r\") as file:\n",
    "        txt = file.read()\n",
    "    return txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163692b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: implement a chunking approach in this cell of your choosing and run the embedding process\n",
    "this chunker will then be used to populate a vector collection.\n",
    "in the subsequent cells we will provide tools to analysis the collection\n",
    "\"\"\"\n",
    "\n",
    "def chunk_text(text: str)->List[str]:\n",
    "    # TODO: replace the chunking function with one of your chosing - starting with a simple fixed length chunker as place holder\n",
    "    clean_text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    return  [clean_text[i:i + 100] for i in range(0, len(clean_text), 100)]\n",
    "\n",
    "chunks = chunk_text(load_example_text())\n",
    "\n",
    "# remove empty chunks\n",
    "chunks = [chunk for chunk in chunks if chunk]\n",
    "\n",
    "print(f\"split example into {len(chunks)} chunks\")\n",
    "\n",
    "for index,chunk in enumerate(chunks):\n",
    "    print(f\"chunk {index}: {chunk}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c83b572",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: run cell -> to populate vector store with the chunks created in the cell above\n",
    "\"\"\"\n",
    "\n",
    "COLLECTION_USER_EXPERIMENTAL_NAME = \"user_experimental\"\n",
    "\n",
    "\n",
    "def drop_and_populate_collection(collection: VectorCollection, chunks: List[str], chroma_client)->None:\n",
    "    remove_collection(chroma_client, COLLECTION_USER_EXPERIMENTAL_NAME)\n",
    "    print(f\"going to embed {len(chunks)} chunks\")\n",
    "    for index, chunk in enumerate(chunks):\n",
    "        print(f\"adding chunk {index}\")\n",
    "        collection.add_item(chunk, f\"id_{index}\")\n",
    "\n",
    "collection_user_experimental = VectorCollection(COLLECTION_USER_EXPERIMENTAL_NAME,\n",
    "                                                chroma_client,\n",
    "                                                OPENAI_API_KEY,\n",
    "                                                embedding_model=OpenAIEmbeddingModel.ADA_002)\n",
    "\n",
    "drop_and_populate_collection(collection_user_experimental, chunks, chroma_client)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150ecd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: explore your vector database with different search terms, tweak your chunking function until you are happy with the retrieval\n",
    "\"\"\"\n",
    "search_term = \"what are the typical foods eaten in belgium\"\n",
    "\n",
    "closest_items = collection_user_experimental.similar_items(search_term, n_results=5)\n",
    "\n",
    "for item in closest_items:\n",
    "    print(f\"distance_to_search_term: {item.distance}, id: {item.id} ,item: {item.text}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c6341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Optional)\n",
    "# visualize the vector database contents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vaia_rag_workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
